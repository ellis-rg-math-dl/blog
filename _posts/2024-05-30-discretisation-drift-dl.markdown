---
layout: post
title:  "The importance of discretisation drift in deep learning"
date:   2024-05-30
categories: meetings
---

Mihaela Rosca discussed with us in this session the difference between discrete steps that are taken by SGD when minimizing 
some function and continuous gradient flow. Bridging this difference results in exciting insights into the possible 
implicit regularizations that are taking place in the SGD optimization that allows it to get to such good generalizing 
solutions.

Presentation can be found [here](http://elarosca.net/dd_ellis_talk_2024.pdf) and it is being updated with new information!